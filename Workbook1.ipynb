{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_score, accuracy_score,f1_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import names\n",
    "from collections import defaultdict\n",
    "import os,re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "...                                                  ...     ...   \n",
       "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13   \n",
       "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...       4   \n",
       "11311  From: westes@netcom.com (Will Estes)\\nSubject:...       3   \n",
       "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1   \n",
       "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...       8   \n",
       "\n",
       "                   target_names  \n",
       "0                   alt.atheism  \n",
       "1                 comp.graphics  \n",
       "2       comp.os.ms-windows.misc  \n",
       "3      comp.sys.ibm.pc.hardware  \n",
       "4         comp.sys.mac.hardware  \n",
       "...                         ...  \n",
       "11309                       NaN  \n",
       "11310                       NaN  \n",
       "11311                       NaN  \n",
       "11312                       NaN  \n",
       "11313                       NaN  \n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train') #remove=('headers', 'footers', 'quotes'))\n",
    "data = pd.Series(newsgroups.data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['text'] + df.columns.tolist()[1:]\n",
    "df['target'] = pd.Series(newsgroups.target)\n",
    "df['target_names'] = pd.Series(newsgroups.target_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "...                                                  ...     ...   \n",
       "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13   \n",
       "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...       4   \n",
       "11311  From: westes@netcom.com (Will Estes)\\nSubject:...       3   \n",
       "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1   \n",
       "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...       8   \n",
       "\n",
       "                   target_names  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "2         comp.sys.mac.hardware  \n",
       "3                 comp.graphics  \n",
       "4                     sci.space  \n",
       "...                         ...  \n",
       "11309                   sci.med  \n",
       "11310     comp.sys.mac.hardware  \n",
       "11311  comp.sys.ibm.pc.hardware  \n",
       "11312             comp.graphics  \n",
       "11313           rec.motorcycles  \n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json (\"https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json\")\n",
    "df1.columns = ['text','target','target_names']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target labels the same:  True\n",
      "text the same:  True\n",
      "target names the same:  False\n"
     ]
    }
   ],
   "source": [
    "print('target labels the same: ',(df['target'] == df1['target']).all())\n",
    "print('text the same: ',(df['text'] == df1['text']).all())\n",
    "print('target names the same: ',(df['target_names'] == df1['target_names']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name_dict = df1[['target','target_names']].drop_duplicates().set_index('target_names')['target'].sort_values().to_dict()\n",
    "target_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1      My brother is in the market for a high-perform...       3\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4      1)    I have an old Jasmine drive which I cann...       4\n",
       "...                                                  ...     ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13\n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "data = pd.Series(newsgroups.data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['text'] + df.columns.tolist()[1:]\n",
    "df['target'] = pd.Series(newsgroups.target)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe:  (18846, 2)\n",
      "number of target variables:  20\n",
      "null target variables:  False\n",
      "null text:  False\n"
     ]
    }
   ],
   "source": [
    "print('shape of dataframe: ', df.shape)\n",
    "print('number of target variables: ',df.target.nunique())\n",
    "print('null target variables: ', df.target.isna().any())\n",
    "print('null text: ',df.text.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a257ff7d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(10,6)})\n",
    "df['target'].hist(bins=df.target.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1      My brother is in the market for a high-perform...       3\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4      1)    I have an old Jasmine drive which I cann...       4\n",
       "...                                                  ...     ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13\n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sure some bashers pens fans are pretty confus...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>brother the market for high-performance video...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>finally you said what you dream about. medite...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>think! its the scsi card doing the dma transf...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>) have old jasmine drive which cannot use with...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>&gt; from: (david nye) &gt; neurology &gt; consultation...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>not isolated ground recepticles (usually unus...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>just installed - cpu clone motherboard, and t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>wouldnt this require hyper-sphere. -space, po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>after tip from gary crum got the phone with \"p...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0       sure some bashers pens fans are pretty confus...      10\n",
       "1       brother the market for high-performance video...       3\n",
       "2       finally you said what you dream about. medite...      17\n",
       "3       think! its the scsi card doing the dma transf...       3\n",
       "4      ) have old jasmine drive which cannot use with...       4\n",
       "...                                                  ...     ...\n",
       "18841  > from: (david nye) > neurology > consultation...      13\n",
       "18842   not isolated ground recepticles (usually unus...      12\n",
       "18843   just installed - cpu clone motherboard, and t...       3\n",
       "18844   wouldnt this require hyper-sphere. -space, po...       1\n",
       "18845  after tip from gary crum got the phone with \"p...       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove emails\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\S*@\\S*\\s?\",\"\",row))\n",
    "\n",
    "#remove single quote marks\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\'\",\"\",row))\n",
    "\n",
    "#make all text lower case\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "#remove numerics\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\d+\",\"\",row))\n",
    "\n",
    "#remove words with fewer than 3 characters\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r'\\b\\w{1,2}\\b', '',row))\n",
    "\n",
    "#remove extra spaces\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\s+\",\" \",row))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      False\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16746</td>\n",
       "      <td>the complete set the adventures buck rogers fo...</td>\n",
       "      <td>6</td>\n",
       "      <td>[complete, set, adventures, buck, rogers, fors...</td>\n",
       "      <td>complete set adventure buck rogers forsale mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7858</td>\n",
       "      <td>have promovie spectrum, seems work very nicel...</td>\n",
       "      <td>3</td>\n",
       "      <td>[promovie, spectrum, seems, work, nicely, vide...</td>\n",
       "      <td>promovie spectrum seems work nicely video wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1866</td>\n",
       "      <td>sorry once again bother those you this newsgr...</td>\n",
       "      <td>13</td>\n",
       "      <td>[sorry, bother, newsgroup, suggestions, might,...</td>\n",
       "      <td>sorry bother newsgroup suggestion might find s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7642</td>\n",
       "      <td>the white house office the press secretary ___...</td>\n",
       "      <td>18</td>\n",
       "      <td>[white, house, office, press, secretary, immed...</td>\n",
       "      <td>white house office press secretary immediate r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "16746  the complete set the adventures buck rogers fo...       6   \n",
       "7858    have promovie spectrum, seems work very nicel...       3   \n",
       "832                                                            0   \n",
       "1866    sorry once again bother those you this newsgr...      13   \n",
       "7642   the white house office the press secretary ___...      18   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "16746  [complete, set, adventures, buck, rogers, fors...   \n",
       "7858   [promovie, spectrum, seems, work, nicely, vide...   \n",
       "832                                                   []   \n",
       "1866   [sorry, bother, newsgroup, suggestions, might,...   \n",
       "7642   [white, house, office, press, secretary, immed...   \n",
       "\n",
       "                                              lemmatized  \n",
       "16746  complete set adventure buck rogers forsale mak...  \n",
       "7858   promovie spectrum seems work nicely video wind...  \n",
       "832                                                       \n",
       "1866   sorry bother newsgroup suggestion might find s...  \n",
       "7642   white house office press secretary immediate r...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instatiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "#tokenize test\n",
    "df['tokenized_text'] = df.apply(lambda row: tokenizer.tokenize(row['text']),axis=1)\n",
    "\n",
    "#define stop words\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "#remove stop words\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#instantiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatize text\n",
    "df['lemmatized'] = df['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "df.lemmatized = df.lemmatized.apply(lambda x: \" \".join(x) )\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sure some bashers pens fans are pretty confus...</td>\n",
       "      <td>10</td>\n",
       "      <td>[sure, bashers, pens, fans, pretty, confused, ...</td>\n",
       "      <td>sure bashers pen fan pretty confused lack kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>brother the market for high-performance video...</td>\n",
       "      <td>3</td>\n",
       "      <td>[brother, market, high, performance, video, ca...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>finally you said what you dream about. medite...</td>\n",
       "      <td>17</td>\n",
       "      <td>[finally, said, dream, mediterranean, new, are...</td>\n",
       "      <td>finally said dream mediterranean new area grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>think! its the scsi card doing the dma transf...</td>\n",
       "      <td>3</td>\n",
       "      <td>[think, scsi, card, dma, transfers, disks, scs...</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>) have old jasmine drive which cannot use with...</td>\n",
       "      <td>4</td>\n",
       "      <td>[old, jasmine, drive, cannot, use, new, system...</td>\n",
       "      <td>old jasmine drive cannot use new system unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>&gt; from: (david nye) &gt; neurology &gt; consultation...</td>\n",
       "      <td>13</td>\n",
       "      <td>[david, nye, neurology, consultation, cheaper,...</td>\n",
       "      <td>david nye neurology consultation cheaper scan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>not isolated ground recepticles (usually unus...</td>\n",
       "      <td>12</td>\n",
       "      <td>[isolated, ground, recepticles, usually, unusu...</td>\n",
       "      <td>isolated ground recepticles usually unusual co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>just installed - cpu clone motherboard, and t...</td>\n",
       "      <td>3</td>\n",
       "      <td>[installed, cpu, clone, motherboard, tried, mo...</td>\n",
       "      <td>installed cpu clone motherboard tried mounting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>wouldnt this require hyper-sphere. -space, po...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wouldnt, require, hyper, sphere, space, point...</td>\n",
       "      <td>wouldnt require hyper sphere space point speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>after tip from gary crum got the phone with \"p...</td>\n",
       "      <td>7</td>\n",
       "      <td>[tip, gary, crum, got, phone, pontiac, systems...</td>\n",
       "      <td>tip gary crum got phone pontiac system pontaic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0       sure some bashers pens fans are pretty confus...      10   \n",
       "1       brother the market for high-performance video...       3   \n",
       "2       finally you said what you dream about. medite...      17   \n",
       "3       think! its the scsi card doing the dma transf...       3   \n",
       "4      ) have old jasmine drive which cannot use with...       4   \n",
       "...                                                  ...     ...   \n",
       "18841  > from: (david nye) > neurology > consultation...      13   \n",
       "18842   not isolated ground recepticles (usually unus...      12   \n",
       "18843   just installed - cpu clone motherboard, and t...       3   \n",
       "18844   wouldnt this require hyper-sphere. -space, po...       1   \n",
       "18845  after tip from gary crum got the phone with \"p...       7   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [sure, bashers, pens, fans, pretty, confused, ...   \n",
       "1      [brother, market, high, performance, video, ca...   \n",
       "2      [finally, said, dream, mediterranean, new, are...   \n",
       "3      [think, scsi, card, dma, transfers, disks, scs...   \n",
       "4      [old, jasmine, drive, cannot, use, new, system...   \n",
       "...                                                  ...   \n",
       "18841  [david, nye, neurology, consultation, cheaper,...   \n",
       "18842  [isolated, ground, recepticles, usually, unusu...   \n",
       "18843  [installed, cpu, clone, motherboard, tried, mo...   \n",
       "18844  [wouldnt, require, hyper, sphere, space, point...   \n",
       "18845  [tip, gary, crum, got, phone, pontiac, systems...   \n",
       "\n",
       "                                              lemmatized  \n",
       "0      sure bashers pen fan pretty confused lack kind...  \n",
       "1      brother market high performance video card sup...  \n",
       "2      finally said dream mediterranean new area grea...  \n",
       "3      think scsi card dma transfer disk scsi card dm...  \n",
       "4      old jasmine drive cannot use new system unders...  \n",
       "...                                                  ...  \n",
       "18841  david nye neurology consultation cheaper scan ...  \n",
       "18842  isolated ground recepticles usually unusual co...  \n",
       "18843  installed cpu clone motherboard tried mounting...  \n",
       "18844  wouldnt require hyper sphere space point speci...  \n",
       "18845  tip gary crum got phone pontiac system pontaic...  \n",
       "\n",
       "[18846 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized_text.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sure some bashers pens fans are pretty confus...</td>\n",
       "      <td>10</td>\n",
       "      <td>[sure, bashers, pens, fans, pretty, confused, ...</td>\n",
       "      <td>sure bashers pen fan pretty confused lack kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>brother the market for high-performance video...</td>\n",
       "      <td>3</td>\n",
       "      <td>[brother, market, high, performance, video, ca...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>finally you said what you dream about. medite...</td>\n",
       "      <td>17</td>\n",
       "      <td>[finally, said, dream, mediterranean, new, are...</td>\n",
       "      <td>finally said dream mediterranean new area grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>think! its the scsi card doing the dma transf...</td>\n",
       "      <td>3</td>\n",
       "      <td>[think, scsi, card, dma, transfers, disks, scs...</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>) have old jasmine drive which cannot use with...</td>\n",
       "      <td>4</td>\n",
       "      <td>[old, jasmine, drive, cannot, use, new, system...</td>\n",
       "      <td>old jasmine drive cannot use new system unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>&gt; from: (david nye) &gt; neurology &gt; consultation...</td>\n",
       "      <td>13</td>\n",
       "      <td>[david, nye, neurology, consultation, cheaper,...</td>\n",
       "      <td>david nye neurology consultation cheaper scan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>not isolated ground recepticles (usually unus...</td>\n",
       "      <td>12</td>\n",
       "      <td>[isolated, ground, recepticles, usually, unusu...</td>\n",
       "      <td>isolated ground recepticles usually unusual co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>just installed - cpu clone motherboard, and t...</td>\n",
       "      <td>3</td>\n",
       "      <td>[installed, cpu, clone, motherboard, tried, mo...</td>\n",
       "      <td>installed cpu clone motherboard tried mounting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>wouldnt this require hyper-sphere. -space, po...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wouldnt, require, hyper, sphere, space, point...</td>\n",
       "      <td>wouldnt require hyper sphere space point speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>after tip from gary crum got the phone with \"p...</td>\n",
       "      <td>7</td>\n",
       "      <td>[tip, gary, crum, got, phone, pontiac, systems...</td>\n",
       "      <td>tip gary crum got phone pontiac system pontaic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0       sure some bashers pens fans are pretty confus...      10   \n",
       "1       brother the market for high-performance video...       3   \n",
       "2       finally you said what you dream about. medite...      17   \n",
       "3       think! its the scsi card doing the dma transf...       3   \n",
       "4      ) have old jasmine drive which cannot use with...       4   \n",
       "...                                                  ...     ...   \n",
       "18841  > from: (david nye) > neurology > consultation...      13   \n",
       "18842   not isolated ground recepticles (usually unus...      12   \n",
       "18843   just installed - cpu clone motherboard, and t...       3   \n",
       "18844   wouldnt this require hyper-sphere. -space, po...       1   \n",
       "18845  after tip from gary crum got the phone with \"p...       7   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [sure, bashers, pens, fans, pretty, confused, ...   \n",
       "1      [brother, market, high, performance, video, ca...   \n",
       "2      [finally, said, dream, mediterranean, new, are...   \n",
       "3      [think, scsi, card, dma, transfers, disks, scs...   \n",
       "4      [old, jasmine, drive, cannot, use, new, system...   \n",
       "...                                                  ...   \n",
       "18841  [david, nye, neurology, consultation, cheaper,...   \n",
       "18842  [isolated, ground, recepticles, usually, unusu...   \n",
       "18843  [installed, cpu, clone, motherboard, tried, mo...   \n",
       "18844  [wouldnt, require, hyper, sphere, space, point...   \n",
       "18845  [tip, gary, crum, got, phone, pontiac, systems...   \n",
       "\n",
       "                                       preprocessed_text  \n",
       "0      sure bashers pen fan pretty confused lack kind...  \n",
       "1      brother market high performance video card sup...  \n",
       "2      finally said dream mediterranean new area grea...  \n",
       "3      think scsi card dma transfer disk scsi card dm...  \n",
       "4      old jasmine drive cannot use new system unders...  \n",
       "...                                                  ...  \n",
       "18841  david nye neurology consultation cheaper scan ...  \n",
       "18842  isolated ground recepticles usually unusual co...  \n",
       "18843  installed cpu clone motherboard tried mounting...  \n",
       "18844  wouldnt require hyper sphere space point speci...  \n",
       "18845  tip gary crum got phone pontiac system pontaic...  \n",
       "\n",
       "[18846 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'lemmatized':'preprocessed_text'},inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings with NaN\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan cells\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sure some bashers pens fans are pretty confus...</td>\n",
       "      <td>10</td>\n",
       "      <td>[sure, bashers, pens, fans, pretty, confused, ...</td>\n",
       "      <td>sure bashers pen fan pretty confused lack kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>brother the market for high-performance video...</td>\n",
       "      <td>3</td>\n",
       "      <td>[brother, market, high, performance, video, ca...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>finally you said what you dream about. medite...</td>\n",
       "      <td>17</td>\n",
       "      <td>[finally, said, dream, mediterranean, new, are...</td>\n",
       "      <td>finally said dream mediterranean new area grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>think! its the scsi card doing the dma transf...</td>\n",
       "      <td>3</td>\n",
       "      <td>[think, scsi, card, dma, transfers, disks, scs...</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>) have old jasmine drive which cannot use with...</td>\n",
       "      <td>4</td>\n",
       "      <td>[old, jasmine, drive, cannot, use, new, system...</td>\n",
       "      <td>old jasmine drive cannot use new system unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18841</td>\n",
       "      <td>&gt; from: (david nye) &gt; neurology &gt; consultation...</td>\n",
       "      <td>13</td>\n",
       "      <td>[david, nye, neurology, consultation, cheaper,...</td>\n",
       "      <td>david nye neurology consultation cheaper scan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18842</td>\n",
       "      <td>not isolated ground recepticles (usually unus...</td>\n",
       "      <td>12</td>\n",
       "      <td>[isolated, ground, recepticles, usually, unusu...</td>\n",
       "      <td>isolated ground recepticles usually unusual co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18843</td>\n",
       "      <td>just installed - cpu clone motherboard, and t...</td>\n",
       "      <td>3</td>\n",
       "      <td>[installed, cpu, clone, motherboard, tried, mo...</td>\n",
       "      <td>installed cpu clone motherboard tried mounting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18844</td>\n",
       "      <td>wouldnt this require hyper-sphere. -space, po...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wouldnt, require, hyper, sphere, space, point...</td>\n",
       "      <td>wouldnt require hyper sphere space point speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18845</td>\n",
       "      <td>after tip from gary crum got the phone with \"p...</td>\n",
       "      <td>7</td>\n",
       "      <td>[tip, gary, crum, got, phone, pontiac, systems...</td>\n",
       "      <td>tip gary crum got phone pontiac system pontaic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0       sure some bashers pens fans are pretty confus...      10   \n",
       "1       brother the market for high-performance video...       3   \n",
       "2       finally you said what you dream about. medite...      17   \n",
       "3       think! its the scsi card doing the dma transf...       3   \n",
       "4      ) have old jasmine drive which cannot use with...       4   \n",
       "...                                                  ...     ...   \n",
       "18841  > from: (david nye) > neurology > consultation...      13   \n",
       "18842   not isolated ground recepticles (usually unus...      12   \n",
       "18843   just installed - cpu clone motherboard, and t...       3   \n",
       "18844   wouldnt this require hyper-sphere. -space, po...       1   \n",
       "18845  after tip from gary crum got the phone with \"p...       7   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [sure, bashers, pens, fans, pretty, confused, ...   \n",
       "1      [brother, market, high, performance, video, ca...   \n",
       "2      [finally, said, dream, mediterranean, new, are...   \n",
       "3      [think, scsi, card, dma, transfers, disks, scs...   \n",
       "4      [old, jasmine, drive, cannot, use, new, system...   \n",
       "...                                                  ...   \n",
       "18841  [david, nye, neurology, consultation, cheaper,...   \n",
       "18842  [isolated, ground, recepticles, usually, unusu...   \n",
       "18843  [installed, cpu, clone, motherboard, tried, mo...   \n",
       "18844  [wouldnt, require, hyper, sphere, space, point...   \n",
       "18845  [tip, gary, crum, got, phone, pontiac, systems...   \n",
       "\n",
       "                                       preprocessed_text  \n",
       "0      sure bashers pen fan pretty confused lack kind...  \n",
       "1      brother market high performance video card sup...  \n",
       "2      finally said dream mediterranean new area grea...  \n",
       "3      think scsi card dma transfer disk scsi card dm...  \n",
       "4      old jasmine drive cannot use new system unders...  \n",
       "...                                                  ...  \n",
       "18841  david nye neurology consultation cheaper scan ...  \n",
       "18842  isolated ground recepticles usually unusual co...  \n",
       "18843  installed cpu clone motherboard tried mounting...  \n",
       "18844  wouldnt require hyper sphere space point speci...  \n",
       "18845  tip gary crum got phone pontiac system pontaic...  \n",
       "\n",
       "[18290 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test validation split\n",
    "\n",
    "X,y = df.preprocessed_text,df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train.to_frame().merge(y_train.to_frame(),left_index=True,right_index=True)\n",
    "val_df = X_val.to_frame().merge(y_val.to_frame(),left_index=True,right_index=True)\n",
    "test_df = X_test.to_frame().merge(y_test.to_frame(),left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(r'Data/train.csv', index = False)\n",
    "val_df.to_csv(r'Data/val.csv', index = False)\n",
    "test_df.to_csv(r'Data/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>australia car enthusiast australia particularl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nothing wrong felix problem didnt dino hard en...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>meg meg sec scsi drive cost since quadra mac a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>suppress secretion prolactin useful case galac...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>still imho rank time greatest blunder mention ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10282</td>\n",
       "      <td>commanded strong courageous terrified discoura...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10283</td>\n",
       "      <td>university wanting buy couple server provide e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10284</td>\n",
       "      <td>looking lead source good window meta file conv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10285</td>\n",
       "      <td>count allan lockridge opinion sale</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10286</td>\n",
       "      <td>actually thats based nhls history game statsti...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       preprocessed_text  target\n",
       "0      australia car enthusiast australia particularl...       7\n",
       "1      nothing wrong felix problem didnt dino hard en...      10\n",
       "2      meg meg sec scsi drive cost since quadra mac a...       3\n",
       "3      suppress secretion prolactin useful case galac...      13\n",
       "4      still imho rank time greatest blunder mention ...      10\n",
       "...                                                  ...     ...\n",
       "10282  commanded strong courageous terrified discoura...      15\n",
       "10283  university wanting buy couple server provide e...       3\n",
       "10284  looking lead source good window meta file conv...       1\n",
       "10285                 count allan lockridge opinion sale      16\n",
       "10286  actually thats based nhls history game statsti...      10\n",
       "\n",
       "[10287 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "val = pd.read_csv('Data/val.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "recall =  make_scorer(recall_score, average='macro')\n",
    "f1 = make_scorer(f1_score, average='macro')\n",
    "scoring={'accuracy':accuracy,'precision':precision,'recall':recall,'f1':f1}\n",
    "\n",
    "scoring.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_confusion_matrix(true, pred):\n",
    "    cm = confusion_matrix(true,pred)\n",
    "    df_cm = pd.DataFrame(cm,\n",
    "                         index = [f'TRUE_{target}' for target in list(range(0,20))],\n",
    "                         columns = [f'PRED_{target}' for target in list(range(0,20))])\n",
    "    sns.heatmap(df_cm, annot=True,annot_kws={'size':10},cmap='Blues',fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "multiclass_confusion_matrix(y_val,pred_val)\n",
    "print(f'{accuracy_score.__name__}: {accuracy_score(y_val, pred_val):.4f}')\n",
    "for scorer in [precision_score,recall_score,f1_score]:\n",
    "    name = scorer.__name__\n",
    "    print(f'{name}: {scorer(y_val, pred_val,average=\"micro\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10747    australia car enthusiast australia particularl...\n",
       "6190     nothing wrong felix problem didnt dino hard en...\n",
       "12339    meg meg sec scsi drive cost since quadra mac a...\n",
       "16797    suppress secretion prolactin useful case galac...\n",
       "14755    still imho rank time greatest blunder mention ...\n",
       "                               ...                        \n",
       "7165     commanded strong courageous terrified discoura...\n",
       "12707    university wanting buy couple server provide e...\n",
       "2444     looking lead source good window meta file conv...\n",
       "18721                   count allan lockridge opinion sale\n",
       "13310    actually thats based nhls history game statsti...\n",
       "Name: preprocessed_text, Length: 10287, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_x_train = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10287x62646 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 662913 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TfidfVectorizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b1d47d61eec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_vect_xtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_x_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'TfidfVectorizer' object is not callable"
     ]
    }
   ],
   "source": [
    "tf_vect_xtrain = tfidf(vect_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn.datasets as skds\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 news groups\n",
    "num_labels = 20\n",
    "vocab_size = 5000\n",
    "batch_size = 100\n",
    " \n",
    "# define Tokenizer with Vocab Size\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    " \n",
    "x_nn_train = tokenizer.texts_to_matrix(X_train, mode='tfidf')\n",
    "x_nn_val = tokenizer.texts_to_matrix(X_val, mode='tfidf')\n",
    "x_nn_test = tokenizer.texts_to_matrix(X_test, mode='tfidf')\n",
    " \n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_nn_train = encoder.transform(y_train)\n",
    "y_nn_val = encoder.transform(y_val)\n",
    "y_nn_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               2560512   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 2,833,428\n",
      "Trainable params: 2,833,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9258 samples, validate on 1029 samples\n",
      "Epoch 1/30\n",
      "9258/9258 [==============================] - 15s 2ms/step - loss: 1.9228 - accuracy: 0.4676 - val_loss: 1.2111 - val_accuracy: 0.6793\n",
      "Epoch 2/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.6908 - accuracy: 0.8122 - val_loss: 1.1518 - val_accuracy: 0.7017\n",
      "Epoch 3/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.3104 - accuracy: 0.9260 - val_loss: 1.2745 - val_accuracy: 0.7026\n",
      "Epoch 4/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.1886 - accuracy: 0.9611 - val_loss: 1.3798 - val_accuracy: 0.7026\n",
      "Epoch 5/30\n",
      "9258/9258 [==============================] - 13s 1ms/step - loss: 0.1024 - accuracy: 0.9797 - val_loss: 1.6107 - val_accuracy: 0.6978\n",
      "Epoch 6/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0800 - accuracy: 0.9863 - val_loss: 1.6909 - val_accuracy: 0.7007\n",
      "Epoch 7/30\n",
      "9258/9258 [==============================] - 13s 1ms/step - loss: 0.1034 - accuracy: 0.9820 - val_loss: 1.8903 - val_accuracy: 0.6754\n",
      "Epoch 8/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0950 - accuracy: 0.9829 - val_loss: 1.7211 - val_accuracy: 0.6822\n",
      "Epoch 9/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0507 - accuracy: 0.9894 - val_loss: 1.8285 - val_accuracy: 0.6822\n",
      "Epoch 10/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0446 - accuracy: 0.9905 - val_loss: 1.9014 - val_accuracy: 0.6890\n",
      "Epoch 11/30\n",
      "9258/9258 [==============================] - 13s 1ms/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 1.8728 - val_accuracy: 0.6939\n",
      "Epoch 12/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0286 - accuracy: 0.9948 - val_loss: 1.9663 - val_accuracy: 0.6842\n",
      "Epoch 13/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0325 - accuracy: 0.9947 - val_loss: 2.0482 - val_accuracy: 0.6783\n",
      "Epoch 14/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 1.9723 - val_accuracy: 0.6676\n",
      "Epoch 15/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 2.1044 - val_accuracy: 0.6686\n",
      "Epoch 16/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 2.3407 - val_accuracy: 0.6589\n",
      "Epoch 17/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 2.3540 - val_accuracy: 0.6628\n",
      "Epoch 18/30\n",
      "9258/9258 [==============================] - 10s 1ms/step - loss: 0.0378 - accuracy: 0.9930 - val_loss: 2.4283 - val_accuracy: 0.6599\n",
      "Epoch 19/30\n",
      "9258/9258 [==============================] - 10s 1ms/step - loss: 0.0449 - accuracy: 0.9898 - val_loss: 2.3494 - val_accuracy: 0.6618\n",
      "Epoch 20/30\n",
      "9258/9258 [==============================] - 10s 1ms/step - loss: 0.1282 - accuracy: 0.9802 - val_loss: 2.6255 - val_accuracy: 0.6618\n",
      "Epoch 21/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0736 - accuracy: 0.9822 - val_loss: 2.3698 - val_accuracy: 0.6628\n",
      "Epoch 22/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0745 - accuracy: 0.9829 - val_loss: 2.4576 - val_accuracy: 0.6754\n",
      "Epoch 23/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 2.4306 - val_accuracy: 0.6812\n",
      "Epoch 24/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0727 - accuracy: 0.9891 - val_loss: 2.4804 - val_accuracy: 0.6754\n",
      "Epoch 25/30\n",
      "9258/9258 [==============================] - 12s 1ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 2.3878 - val_accuracy: 0.6764\n",
      "Epoch 26/30\n",
      "9258/9258 [==============================] - 13s 1ms/step - loss: 0.0259 - accuracy: 0.9935 - val_loss: 2.4622 - val_accuracy: 0.6715\n",
      "Epoch 27/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0479 - accuracy: 0.9903 - val_loss: 2.8102 - val_accuracy: 0.6725\n",
      "Epoch 28/30\n",
      "9258/9258 [==============================] - 13s 1ms/step - loss: 0.0443 - accuracy: 0.9900 - val_loss: 2.8322 - val_accuracy: 0.6715\n",
      "Epoch 29/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 2.8345 - val_accuracy: 0.6832\n",
      "Epoch 30/30\n",
      "9258/9258 [==============================] - 11s 1ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 2.8798 - val_accuracy: 0.6803\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(x_nn_train, y_nn_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430/3430 [==============================] - 1s 255us/step\n",
      "Test accuracy: 0.6778425574302673\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_files_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-471337581a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_nn_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Actual label:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted label: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_files_names' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(x_nn_val, y_nn_val,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    " \n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "text_labels = encoder.classes_\n",
    " \n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_nn_val[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
    "    print(test_files_names.iloc[i])\n",
    "    print('Actual label:' + test_tags.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=10)\n",
    "# train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abolish</th>\n",
       "      <th>...</th>\n",
       "      <th>youve</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>yup</th>\n",
       "      <th>yzerman</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  aaron   ab  abandon  abandoned  abc  abiding  ability      able  \\\n",
       "0  0.0    0.0  0.0      0.0        0.0  0.0      0.0      0.0  0.000000   \n",
       "1  0.0    0.0  0.0      0.0        0.0  0.0      0.0      0.0  0.000000   \n",
       "2  0.0    0.0  0.0      0.0        0.0  0.0      0.0      0.0  0.088768   \n",
       "3  0.0    0.0  0.0      0.0        0.0  0.0      0.0      0.0  0.000000   \n",
       "4  0.0    0.0  0.0      0.0        0.0  0.0      0.0      0.0  0.000000   \n",
       "\n",
       "   abolish  ...  youve  yugoslavia  yup  yzerman  zealand  zero  zionist  zip  \\\n",
       "0      0.0  ...    0.0         0.0  0.0      0.0      0.0   0.0      0.0  0.0   \n",
       "1      0.0  ...    0.0         0.0  0.0      0.0      0.0   0.0      0.0  0.0   \n",
       "2      0.0  ...    0.0         0.0  0.0      0.0      0.0   0.0      0.0  0.0   \n",
       "3      0.0  ...    0.0         0.0  0.0      0.0      0.0   0.0      0.0  0.0   \n",
       "4      0.0  ...    0.0         0.0  0.0      0.0      0.0   0.0      0.0  0.0   \n",
       "\n",
       "   zone  zoom  \n",
       "0   0.0   0.0  \n",
       "1   0.0   0.0  \n",
       "2   0.0   0.0  \n",
       "3   0.0   0.0  \n",
       "4   0.0   0.0  \n",
       "\n",
       "[5 rows x 7885 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                    \n",
    "tfidf_train_sparse = tfidf.fit_transform(train.preprocessed_text)\n",
    "tfidf_train_df = pd.DataFrame(tfidf_train_sparse.toarray(), \n",
    "                        columns=tfidf.get_feature_names())\n",
    "\n",
    "tfidf_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10287,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_log_reg(train_features, test_features, y_train, y_test,  alpha = 1e-4, confusion = False, return_f1 = False, verbose = True):\n",
    "    metrics = np.zeros(5)\n",
    "    for _ in range(10):\n",
    "        log_reg = SGDClassifier(loss = 'log', alpha = alpha, n_jobs = -1, penalty = 'l2')\n",
    "        log_reg.fit(train_features, y_train)\n",
    "        y_test_prob = log_reg.predict_proba(test_features)[:,1]\n",
    "        metrics += print_model_metrics(y_test, y_test_prob, confusion = confusion, verbose = False, return_metrics = True)\n",
    "    metrics /=10\n",
    "    if verbose:\n",
    "        print('F1: {:.3f} | Pr: {:.3f} | Re: {:.3f} | AUC: {:.3f} | Accuracy: {:.3f} \\n'.format(*metrics))\n",
    "    if return_f1:\n",
    "        return metrics[0]\n",
    "    return log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_metrics(y_test, y_test_prob, confusion = False, verbose = True, return_metrics = False):\n",
    "\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, y_test_prob, pos_label = 1)\n",
    "    \n",
    "    #Find the threshold value that gives the best F1 Score\n",
    "    best_f1_index =np.argmax([calc_f1(p_r) for p_r in zip(precision, recall)])\n",
    "    best_threshold, best_precision, best_recall = threshold[best_f1_index], precision[best_f1_index], recall[best_f1_index]\n",
    "    \n",
    "    # Calulcate predictions based on the threshold value\n",
    "    y_test_pred = np.where(y_test_prob > best_threshold, 1, 0)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    f1 = f1_score(y_test, y_test_pred, pos_label = 1, average = 'micro')\n",
    "    roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    \n",
    "    if confusion:\n",
    "        # Calculate and Display the confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "        plt.title('Confusion Matrix')\n",
    "        sns.set(font_scale=1.0) #for label size\n",
    "        sns.heatmap(cm, annot = True, fmt = 'd', xticklabels = ['No Clickbait', 'Clickbait'], yticklabels = ['No Clickbait', 'Clickbait'], annot_kws={\"size\": 14}, cmap = 'Blues')# font size\n",
    "\n",
    "        plt.xlabel('Truth')\n",
    "        plt.ylabel('Prediction')\n",
    "        \n",
    "    if verbose:\n",
    "        print('F1: {:.3f} | Pr: {:.3f} | Re: {:.3f} | AUC: {:.3f} | Accuracy: {:.3f} \\n'.format(f1, best_precision, best_recall, roc_auc, acc))\n",
    "    \n",
    "    if return_metrics:\n",
    "        return np.array([f1, best_precision, best_recall, roc_auc, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1(p_and_r):\n",
    "    p, r = p_and_r\n",
    "    return (2*p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The path to the Magnitude file at './vectors/glove.6B.100d.magnitude' could not be found. Also failed to find a valid remote model at the following URL: http://magnitude.plasticity.ai/./vectors/glove.6B.100d.magnitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymagnitude/__init__.py\u001b[0m in \u001b[0;36mdownload_model\u001b[0;34m(model, download_dir, remote_path, log, _download, _local)\u001b[0m\n\u001b[1;32m   2153\u001b[0m                     \u001b[0mremote_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_file_name_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2155\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-d64c84a9d92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymagnitude\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./vectors/glove.6B.100d.magnitude\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mavg_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymagnitude/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, stream, stream_options, lazy_loading, blocking, normalized, use_numpy, case_insensitive, pad_to_length, truncate_left, pad_left, placeholders, ngram_oov, supress_warnings, batch_size, eager, language, dtype, devices, temp_dir, log, _namespace, _number_of_values)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 self.path) and not self.memory_db:\n\u001b[1;32m    351\u001b[0m             self.path = MagnitudeUtils.download_model(\n\u001b[0;32m--> 352\u001b[0;31m                 self.path, log=self.log, _local=True)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# Open a read-only file descriptor against the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymagnitude/__init__.py\u001b[0m in \u001b[0;36mdownload_model\u001b[0;34m(model, download_dir, remote_path, log, _download, _local)\u001b[0m\n\u001b[1;32m   2171\u001b[0m                     raise RuntimeError(\n\u001b[1;32m   2172\u001b[0m                         \u001b[0;34m\"The path to the Magnitude file at '\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"' could not be found. Also failed to find a valid remote model at the following URL: \"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2173\u001b[0;31m                         remote_file_path)\n\u001b[0m\u001b[1;32m   2174\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m                     raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The path to the Magnitude file at './vectors/glove.6B.100d.magnitude' could not be found. Also failed to find a valid remote model at the following URL: http://magnitude.plasticity.ai/./vectors/glove.6B.100d.magnitude"
     ]
    }
   ],
   "source": [
    "# We'll use Average Glove here \n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "glove = Magnitude(\"./vectors/glove.6B.100d.magnitude\")\n",
    "def avg_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df.title.values):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
