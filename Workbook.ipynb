{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_score, accuracy_score,f1_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import names\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1  My brother is in the market for a high-perform...       3\n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4  1)    I have an old Jasmine drive which I cann...       4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "data = pd.Series(newsgroups.data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['text'] + df.columns.tolist()[1:]\n",
    "df['target'] = pd.Series(newsgroups.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe:  (18846, 2)\n",
      "number of target variables:  20\n",
      "null target variables:  False\n",
      "null text:  False\n"
     ]
    }
   ],
   "source": [
    "print('shape of dataframe: ', df.shape)\n",
    "print('number of target variables: ',df.target.nunique())\n",
    "print('null target variables: ', df.target.isna().any())\n",
    "print('null text: ',df.text.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\nI am sure some bashers of Pens fans are pr...\n",
       "1        My brother is in the market for a high-perform...\n",
       "2        \\n\\n\\n\\n\\tFinally you said what you dream abou...\n",
       "3        \\nThink!\\n\\nIt's the SCSI card doing the DMA t...\n",
       "4        1)    I have an old Jasmine drive which I cann...\n",
       "                               ...                        \n",
       "18841    DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "18842    \\nNot in isolated ground recepticles (usually ...\n",
       "18843    I just installed a DX2-66 CPU in a clone mothe...\n",
       "18844    \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "18845    After a tip from Gary Crum (crum@fcom.cc.utah....\n",
       "Name: text, Length: 18846, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18837 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1      My brother is in the market for a high-perform...       3\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4      1)    I have an old Jasmine drive which I cann...       4\n",
       "...                                                  ...     ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13\n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7\n",
       "\n",
       "[18837 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df.text != ' ']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7effe40b5fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(10,6)})\n",
    "df['target'].hist(bins=df.target.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove emails\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\S*@\\S*\\s?\",\"\",row))\n",
    "\n",
    "#remove extra spaces\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\s+\",\" \",row))\n",
    "\n",
    "# #remove single quote marks\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\'\",\"\",row))\n",
    "\n",
    "#make all text lower case\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "#remove empty rows\n",
    "# df['text'] = df[df.text != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      False\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17924</th>\n",
       "      <td>there is a library of map projections in: cha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[library, map, projections, charon, er, usgs, ...</td>\n",
       "      <td>library map projection charon er usgs gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>: : &gt;its quite possible that a buyer and selle...</td>\n",
       "      <td>18</td>\n",
       "      <td>[quite, possible, buyer, seller, trust, third,...</td>\n",
       "      <td>quite possible buyer seller trust third party ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>theres another point to be made. those who ha...</td>\n",
       "      <td>19</td>\n",
       "      <td>[theres, another, point, made, inside, burning...</td>\n",
       "      <td>there another point made inside burning house ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>chicago from what i have read is projected to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[chicago, read, projected, run, 4m, 386, highe...</td>\n",
       "      <td>chicago read projected run 4m 386 higher defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>liberals and supporters of clinton say that c...</td>\n",
       "      <td>16</td>\n",
       "      <td>[liberals, supporters, clinton, say, costs, ma...</td>\n",
       "      <td>liberal supporter clinton say cost made action...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "17924   there is a library of map projections in: cha...       1   \n",
       "7724   : : >its quite possible that a buyer and selle...      18   \n",
       "5116    theres another point to be made. those who ha...      19   \n",
       "5377   chicago from what i have read is projected to ...       2   \n",
       "2366    liberals and supporters of clinton say that c...      16   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "17924  [library, map, projections, charon, er, usgs, ...   \n",
       "7724   [quite, possible, buyer, seller, trust, third,...   \n",
       "5116   [theres, another, point, made, inside, burning...   \n",
       "5377   [chicago, read, projected, run, 4m, 386, highe...   \n",
       "2366   [liberals, supporters, clinton, say, costs, ma...   \n",
       "\n",
       "                                              lemmatized  \n",
       "17924          library map projection charon er usgs gov  \n",
       "7724   quite possible buyer seller trust third party ...  \n",
       "5116   there another point made inside burning house ...  \n",
       "5377   chicago read projected run 4m 386 higher defin...  \n",
       "2366   liberal supporter clinton say cost made action...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instatiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "#tokenize test\n",
    "df['tokenized_text'] = df.apply(lambda row: tokenizer.tokenize(row['text']),axis=1)\n",
    "\n",
    "#define stop words\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "#remove stop words\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#instantiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatize text\n",
    "df['lemmatized'] = df['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "df.lemmatized = df.lemmatized.apply(lambda x: \" \".join(x) )\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized_text.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test validation split\n",
    "\n",
    "X,y = df.lemmatized,df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = make_scorer(accuracy_score, average='macro')\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "recall =  make_scorer(recall_score, average='macro')\n",
    "f1 = make_scorer(f1_score, average='macro')\n",
    "scoring={'accuracy':accuracy,'precision':precision,'recall':recall,'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pipeline for logistic regression\n",
    "\n",
    "pipe_logreg = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters_logreg = {\n",
    "    'tfidf__min_df': [0.001,0.005,0.01],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__max_features': [None, 5000, 10000, 50000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    \"clf__C\": [0.01, 0.1, 1,10],\n",
    "    \"clf__class_weight\": ['balanced'],\n",
    "    \"clf__solver\": ['newton-cg', 'lbfgs', 'sag'],\n",
    "#     \"clf__l1_ratio\":[0,0.2,0.4,0.6,0.8,1],\n",
    "    \"clf__multi_class\":['multinomial']\n",
    "}\n",
    "\n",
    "gs_logreg = GridSearchCV(estimator=pipe_logreg,\n",
    "            param_grid=parameters_logreg,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 85.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed: 93.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.708\n",
      "\n",
      "Best params:\n",
      " {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__multi_class': 'multinomial', 'clf__solver': 'newton-cg', 'tfidf__max_df': 0.5, 'tfidf__max_features': None, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "# Fit using grid search\n",
    "best_model = gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_logreg.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'tfidf', 'clf', 'tfidf__analyzer', 'tfidf__binary', 'tfidf__decode_error', 'tfidf__dtype', 'tfidf__encoding', 'tfidf__input', 'tfidf__lowercase', 'tfidf__max_df', 'tfidf__max_features', 'tfidf__min_df', 'tfidf__ngram_range', 'tfidf__norm', 'tfidf__preprocessor', 'tfidf__smooth_idf', 'tfidf__stop_words', 'tfidf__strip_accents', 'tfidf__sublinear_tf', 'tfidf__token_pattern', 'tfidf__tokenizer', 'tfidf__use_idf', 'tfidf__vocabulary', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__l1_ratio', 'clf__max_iter', 'clf__multi_class', 'clf__n_jobs', 'clf__penalty', 'clf__random_state', 'clf__solver', 'clf__tol', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_logreg.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10368 candidates, totalling 51840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 78.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 90.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 104.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 118.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 133.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 149.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 167.0min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 185.1min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 204.1min\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 224.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 244.8min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 266.5min\n",
      "[Parallel(n_jobs=-1)]: Done 31234 tasks      | elapsed: 289.2min\n",
      "[Parallel(n_jobs=-1)]: Done 33784 tasks      | elapsed: 312.9min\n",
      "[Parallel(n_jobs=-1)]: Done 36434 tasks      | elapsed: 337.4min\n",
      "[Parallel(n_jobs=-1)]: Done 39184 tasks      | elapsed: 362.9min\n",
      "[Parallel(n_jobs=-1)]: Done 42034 tasks      | elapsed: 389.4min\n",
      "[Parallel(n_jobs=-1)]: Done 44984 tasks      | elapsed: 416.7min\n",
      "[Parallel(n_jobs=-1)]: Done 48034 tasks      | elapsed: 445.0min\n",
      "[Parallel(n_jobs=-1)]: Done 51184 tasks      | elapsed: 474.2min\n",
      "[Parallel(n_jobs=-1)]: Done 51840 out of 51840 | elapsed: 480.3min finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-02d312376fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Fit using grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Best accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                 raise ValueError(\"min_samples_split must be an integer \"\n\u001b[1;32m    228\u001b[0m                                  \u001b[0;34m\"greater than 1 or a float in (0.0, 1.0]; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'range'"
     ]
    }
   ],
   "source": [
    "#pipeline for decision tree\n",
    "\n",
    "pipe_tree = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "parameters_tree = {\n",
    "    'tfidf__min_df': [0.001,0.005,0.01],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__max_features': [None, 5000, 10000, 50000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"clf__splitter\": ['best','random'],\n",
    "    \"clf__max_features\": [None, 5000, 10000, 50000],\n",
    "    \"clf__max_depth\":[10,15,20,30,40,50,70,90,100],\n",
    "    \"clf__min_samples_split\" : [10,50,100,150]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(estimator=pipe_tree,\n",
    "            param_grid=parameters_tree,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_tree.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_tree.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for random forest\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "parameters_rf = {\n",
    "    'tfidf__min_df': [0.001,0.005,0.01],\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__max_features': [None, 5000, 10000, 50000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"clf__max_features\": [None, 5000, 10000, 50000],\n",
    "    \"clf__max_depth\":[10,20,40,50,100],\n",
    "    \"clf__min_samples_split\" : [range(10,500,50)]\n",
    "}\n",
    "\n",
    "rf_tree = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=parameters_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = rf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % rf_tree.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', rf_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_sparse_classifier, tfidf\n",
    "from sklearn import metrics\n",
    "from hyperopt import tpe\n",
    "\n",
    "\n",
    "estim = HyperoptEstimator( classifier=any_sparse_classifier('clf'), \n",
    "                            preprocessing=[tfidf('tfidf')],\n",
    "                            algo=tpe.suggest, trial_timeout=500)\n",
    "\n",
    "estim.fit( X_train, y_train )\n",
    "\n",
    "print( estim.score( X_val, y_val ) )\n",
    "# <<show score here>>\n",
    "print( estim.best_model() )\n",
    "# <<show model here>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
