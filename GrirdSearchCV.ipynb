{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_score, accuracy_score,f1_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import names\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1  My brother is in the market for a high-perform...       3\n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4  1)    I have an old Jasmine drive which I cann...       4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "data = pd.Series(newsgroups.data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['text'] + df.columns.tolist()[1:]\n",
    "df['target'] = pd.Series(newsgroups.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe:  (18846, 2)\n",
      "number of target variables:  20\n",
      "null target variables:  False\n",
      "null text:  False\n"
     ]
    }
   ],
   "source": [
    "print('shape of dataframe: ', df.shape)\n",
    "print('number of target variables: ',df.target.nunique())\n",
    "print('null target variables: ', df.target.isna().any())\n",
    "print('null text: ',df.text.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sure some bashers pens fans are pretty confus...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brother the market for high-performance video...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally you said what you dream about. medite...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>think! its the scsi card doing the dma transf...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>) have old jasmine drive which cannot use with...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>&gt; from: (david nye) &gt; neurology &gt; consultation...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>not isolated ground recepticles (usually unus...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>just installed - cpu clone motherboard, and t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>wouldnt this require hyper-sphere. -space, po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>after tip from gary crum got the phone with \"p...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0       sure some bashers pens fans are pretty confus...      10\n",
       "1       brother the market for high-performance video...       3\n",
       "2       finally you said what you dream about. medite...      17\n",
       "3       think! its the scsi card doing the dma transf...       3\n",
       "4      ) have old jasmine drive which cannot use with...       4\n",
       "...                                                  ...     ...\n",
       "18841  > from: (david nye) > neurology > consultation...      13\n",
       "18842   not isolated ground recepticles (usually unus...      12\n",
       "18843   just installed - cpu clone motherboard, and t...       3\n",
       "18844   wouldnt this require hyper-sphere. -space, po...       1\n",
       "18845  after tip from gary crum got the phone with \"p...       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove emails\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\S*@\\S*\\s?\",\"\",row))\n",
    "\n",
    "#remove single quote marks\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\'\",\"\",row))\n",
    "\n",
    "#make all text lower case\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "#remove numerics\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\d+\",\"\",row))\n",
    "\n",
    "#remove words with fewer than 3 characters\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r'\\b\\w{1,2}\\b', '',row))\n",
    "\n",
    "#remove extra spaces\n",
    "df['text'] = df['text'].apply(lambda row: re.sub(r\"\\s+\",\" \",row))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>predict that the outcome the study what went ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[predict, outcome, study, went, wrong, federal...</td>\n",
       "      <td>predict outcome study went wrong federal assau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15402</th>\n",
       "      <td>where did you hear this? printed book somewhe...</td>\n",
       "      <td>5</td>\n",
       "      <td>[hear, printed, book, somewhere, throw, away, ...</td>\n",
       "      <td>hear printed book somewhere throw away book ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>xperts, some simple questions for you: ive se...</td>\n",
       "      <td>5</td>\n",
       "      <td>[xperts, simple, questions, ive, seen, lot, di...</td>\n",
       "      <td>xperts simple question ive seen lot different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>you remember game the nlcs, after the dodgers...</td>\n",
       "      <td>9</td>\n",
       "      <td>[remember, game, nlcs, dodgers, defeated, mets...</td>\n",
       "      <td>remember game nlcs dodger defeated mets ugh du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>big for .sig? way! keith \" home the billdboar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[big, sig, way, keith, home, billdboard, sig, ...</td>\n",
       "      <td>big sig way keith home billdboard sig file rya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "3612    predict that the outcome the study what went ...      16   \n",
       "15402   where did you hear this? printed book somewhe...       5   \n",
       "12785   xperts, some simple questions for you: ive se...       5   \n",
       "9346    you remember game the nlcs, after the dodgers...       9   \n",
       "2915    big for .sig? way! keith \" home the billdboar...       0   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "3612   [predict, outcome, study, went, wrong, federal...   \n",
       "15402  [hear, printed, book, somewhere, throw, away, ...   \n",
       "12785  [xperts, simple, questions, ive, seen, lot, di...   \n",
       "9346   [remember, game, nlcs, dodgers, defeated, mets...   \n",
       "2915   [big, sig, way, keith, home, billdboard, sig, ...   \n",
       "\n",
       "                                              lemmatized  \n",
       "3612   predict outcome study went wrong federal assau...  \n",
       "15402  hear printed book somewhere throw away book ac...  \n",
       "12785  xperts simple question ive seen lot different ...  \n",
       "9346   remember game nlcs dodger defeated mets ugh du...  \n",
       "2915   big sig way keith home billdboard sig file rya...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instatiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "#tokenize test\n",
    "df['tokenized_text'] = df.apply(lambda row: tokenizer.tokenize(row['text']),axis=1)\n",
    "\n",
    "#define stop words\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "#remove stop words\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#instantiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatize text\n",
    "df['lemmatized'] = df['tokenized_text'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "df.lemmatized = df.lemmatized.apply(lambda x: \" \".join(x) )\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized_text.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test validation split\n",
    "\n",
    "X,y = df.lemmatized,df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.702\n",
      "\n",
      "Best params:\n",
      " {'clf__class_weight': 'balanced', 'clf__max_iter': 80, 'clf__multi_class': 'ovr', 'clf__solver': 'lbfgs', 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for logistic regression\n",
    "\n",
    "pipe_logreg = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters_logreg = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5,1],\n",
    "#     'tfidf__max_features': [None, 5000, 10000, 50000],\n",
    "    'tfidf__ngram_range': [(1,1),(1, 2)],  # unigrams or bigrams\n",
    "#     \"clf__C\": [0.1,1,10],\n",
    "    \"clf__class_weight\": ['balanced'],\n",
    "    \"clf__solver\": ['newton-cg','lbfgs'],\n",
    "    \"clf__max_iter\":[80,100],\n",
    "    \"clf__multi_class\":['multinomial','ovr']\n",
    "}\n",
    "\n",
    "gs_logreg = GridSearchCV(estimator=pipe_logreg,\n",
    "            param_grid=parameters_logreg,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_logreg.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    7.1s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.481\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 250, 'clf__min_samples_split': 200, 'tfidf__max_df': 0.75, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for decision tree\n",
    "\n",
    "pipe_tree = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "parameters_tree = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.75],\n",
    "    'tfidf__ngram_range': [(1, 1)],  # unigrams or bigrams\n",
    "    \"clf__criterion\": [\"gini\"],\n",
    "    \"clf__max_depth\":[150,250],\n",
    "    \"clf__min_samples_split\" : [200]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(estimator=pipe_tree,\n",
    "            param_grid=parameters_tree,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_tree.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_tree.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for random forest\n",
    "\n",
    "# pipe_rf = Pipeline([\n",
    "#      ('tfidf', TfidfVectorizer()),\n",
    "#     ('clf', RandomForestClassifier())\n",
    "# ])\n",
    "# parameters_rf = {\n",
    "#     'tfidf__min_df': [3,5,10],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "#     \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"clf__max_depth\":[75,100,150],\n",
    "#     \"clf__min_samples_split\" : [75,100,150]\n",
    "# }\n",
    "\n",
    "# gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "#             param_grid=parameters_rf,\n",
    "#             scoring='accuracy',\n",
    "#             cv=KFold(5,shuffle=True,random_state=42), \n",
    "#             return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# # Fit using grid search\n",
    "# best_model = gs_rf.fit(X_train, y_train)\n",
    "\n",
    "# # Best accuracy\n",
    "# print('Best accuracy: %.3f' % gs_rf.best_score_)\n",
    "\n",
    "# # Best params\n",
    "# print('\\nBest params:\\n', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.530\n",
      "\n",
      "Best params:\n",
      " {'svd__n_components': 150, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for NaiveBayes\n",
    "\n",
    "pipe_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "    ('clf',   GaussianNB()),\n",
    "])\n",
    "\n",
    "parameters_nb = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    \"svd__n_components\": [100,150,250,500],\n",
    "}\n",
    "\n",
    "gs_nb = GridSearchCV(estimator=pipe_nb,\n",
    "            param_grid=parameters_nb,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_nb.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_nb.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.687\n",
      "\n",
      "Best params:\n",
      " {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__decision_function_shape': 'ovo', 'clf__gamma': 1e-05, 'clf__kernel': 'linear', 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for svm\n",
    "from sklearn.svm import SVC\n",
    "pipe_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf',   SVC()),\n",
    "])\n",
    "\n",
    "parameters_svm = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 2)],  # unigrams or bigrams\n",
    "    \"clf__C\": [1],\n",
    "    \"clf__kernel\":['linear'],\n",
    "    \"clf__class_weight\" : ['balanced'],\n",
    "    \"clf__decision_function_shape\":['ovo'],\n",
    "    \"clf__gamma\":[0.00001,0.00005,0.0001]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=parameters_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_svm.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.633\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 500, 'clf__min_samples_split': 40, 'tfidf__max_df': 1.0, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for random forest take 2\n",
    "\n",
    "pipe_rf2 = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "parameters_rf2 = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [1.0],\n",
    "    'tfidf__ngram_range': [(1, 2)],  #bigrams\n",
    "    \"clf__criterion\": [\"gini\"],\n",
    "    \"clf__max_depth\":[150,250,500],\n",
    "    \"clf__min_samples_split\" : [40,50,75]\n",
    "}\n",
    "\n",
    "gs_rf2 = GridSearchCV(estimator=pipe_rf2,\n",
    "            param_grid=parameters_rf2,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_rf2.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_rf2.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.158\n",
      "\n",
      "Best params:\n",
      " {'clf__metric': 'minkowski', 'clf__n_neighbors': 1, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for knn\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 0.001)),\n",
    "#     ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "    ('clf',   KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "parameters_knn = {\n",
    "#     'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1,1),(1, 2)],  #  bigrams\n",
    "#     \"svd__n_components\": [100,250,500],\n",
    "    \"clf__n_neighbors\": [1,3,5,10],\n",
    "    \"clf__metric\": ['minkowski', 'euclidean','wminkowski']\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(estimator=pipe_knn,\n",
    "            param_grid=parameters_knn,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_knn.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 45.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.506\n",
      "\n",
      "Best params:\n",
      " {'clf__metric': 'minkowski', 'clf__n_neighbors': 10, 'svd__n_components': 100, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for knn\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 0.001)),\n",
    "    ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "    ('clf',   KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "parameters_knn = {\n",
    "#     'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1,1),(1, 2)],  #  bigrams\n",
    "    \"svd__n_components\": [100,250,500],\n",
    "    \"clf__n_neighbors\": [1,3,5,10],\n",
    "    \"clf__metric\": ['minkowski', 'euclidean','wminkowski']\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(estimator=pipe_knn,\n",
    "            param_grid=parameters_knn,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_knn.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "#pipeline for xgboost\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=0.001)),\n",
    "    ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "    ('clf',   XGBClassifier(objective='multi:softmax', num_class=20)),\n",
    "])\n",
    "\n",
    "parameters_xgb = {\n",
    "#     'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1,2),(1, 2)],  #  bigrams\n",
    "    \"svd__n_components\": [500],\n",
    "    \"clf__n_estimators\": [500],\n",
    "    \"clf__learning_rate\":[0.01,0.1,1],\n",
    "    \"clf__min_samples_split\" : [50,100]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=pipe_xgb,\n",
    "            param_grid=parameters_xgb,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_xgb.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
