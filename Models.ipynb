{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, precision_score, accuracy_score,f1_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import names\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test validation split\n",
    "\n",
    "# X,y = df.lemmatized,df.target\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_val = pd.read_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theyve sold cray realised spending two year nu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks doc info turn leave colormap update fra...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manual transmission speed difficult engage gea...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recently compiled xrpl source using gcc sun ev...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kratz comment show otherwise bingo question gl...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>yeah dont use clutch time either ive done ford...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>hello trouble using tcp onpredir printer redir...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>supposed signify prefer companionship person e...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>greg flame definitely intended bill making fun...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>norman green claim lost money last three year ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      preprocessed_text  target\n",
       "0     theyve sold cray realised spending two year nu...       4\n",
       "1     thanks doc info turn leave colormap update fra...       5\n",
       "2     manual transmission speed difficult engage gea...       7\n",
       "3     recently compiled xrpl source using gcc sun ev...       5\n",
       "4     kratz comment show otherwise bingo question gl...      16\n",
       "...                                                 ...     ...\n",
       "4568  yeah dont use clutch time either ive done ford...       7\n",
       "4569  hello trouble using tcp onpredir printer redir...       2\n",
       "4570  supposed signify prefer companionship person e...      18\n",
       "4571  greg flame definitely intended bill making fun...      13\n",
       "4572  norman green claim lost money last three year ...      10\n",
       "\n",
       "[4573 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_train,df_test,df_val]\n",
    "for df in df_list:\n",
    "    df.astype({'target': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10287 entries, 0 to 10286\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   preprocessed_text  10287 non-null  object\n",
      " 1   target             10287 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 160.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['preprocessed_text'], df_train['target']\n",
    "X_test, y_test = df_test['preprocessed_text'], df_test['target']\n",
    "X_val, y_val = df_val['preprocessed_text'], df_val['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7\n",
       "1        10\n",
       "2         3\n",
       "3        13\n",
       "4        10\n",
       "         ..\n",
       "10282    15\n",
       "10283     3\n",
       "10284     1\n",
       "10285    16\n",
       "10286    10\n",
       "Name: target, Length: 10287, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 13.2min\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 59.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.711\n",
      "\n",
      "Best params:\n",
      " {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__max_iter': 80, 'clf__multi_class': 'multinomial', 'clf__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__max_features': None, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#pipeline for logistic regression\n",
    "\n",
    "pipe_logreg = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters_logreg = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.5,0.75,1],\n",
    "    'tfidf__max_features': [None, 5000, 10000, 50000],\n",
    "    'tfidf__ngram_range': [(1,1),(1, 2)],  # unigrams or bigrams\n",
    "    \"clf__C\": [0.1,1,10],\n",
    "    \"clf__class_weight\": ['balanced'],\n",
    "    \"clf__solver\": ['newton-cg','lbfgs'],\n",
    "    \"clf__max_iter\":[80,100],\n",
    "    \"clf__multi_class\":['multinomial','ovr']\n",
    "}\n",
    "\n",
    "gs_logreg = GridSearchCV(estimator=pipe_logreg,\n",
    "            param_grid=parameters_logreg,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_logreg.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   44.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.492\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 300, 'clf__min_samples_split': 150, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for decision tree\n",
    "\n",
    "pipe_tree = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "parameters_tree = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.75],\n",
    "    'tfidf__ngram_range': [(1, 1)],  # unigrams or bigrams\n",
    "    \"clf__criterion\": [\"gini\"],\n",
    "    \"clf__max_depth\":[250,300,500],\n",
    "    \"clf__min_samples_split\" : [150,200,250]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(estimator=pipe_tree,\n",
    "            param_grid=parameters_tree,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_tree.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_tree.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for random forest\n",
    "\n",
    "# pipe_rf = Pipeline([\n",
    "#      ('tfidf', TfidfVectorizer()),\n",
    "#     ('clf', RandomForestClassifier())\n",
    "# ])\n",
    "# parameters_rf = {\n",
    "#     'tfidf__min_df': [3,5,10],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "#     \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"clf__max_depth\":[75,100,150],\n",
    "#     \"clf__min_samples_split\" : [75,100,150]\n",
    "# }\n",
    "\n",
    "# gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "#             param_grid=parameters_rf,\n",
    "#             scoring='accuracy',\n",
    "#             cv=KFold(5,shuffle=True,random_state=42), \n",
    "#             return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# # Fit using grid search\n",
    "# best_model = gs_rf.fit(X_train, y_train)\n",
    "\n",
    "# # Best accuracy\n",
    "# print('Best accuracy: %.3f' % gs_rf.best_score_)\n",
    "\n",
    "# # Best params\n",
    "# print('\\nBest params:\\n', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    9.1s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.698\n",
      "\n",
      "Best params:\n",
      " {'vect__min_df': 0.001, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for NaiveBayes\n",
    "\n",
    "pipe_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf',   MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters_nb = {\n",
    "    'vect__ngram_range': [(1,1),(1,2)],\n",
    "    'vect__min_df': [0.001]\n",
    "#     'tfidf__min_df': [0.001]\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)]  # unigrams or bigrams\n",
    "\n",
    "}\n",
    "\n",
    "gs_nb = GridSearchCV(estimator=pipe_nb,\n",
    "            param_grid=parameters_nb,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_nb.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_nb.best_score_)\n",
    "#\n",
    "# # # Best params\n",
    "print('\\nBest params:\\n', gs_nb.best_params_)\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(pipe_nb, X_train, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.694\n",
      "\n",
      "Best params:\n",
      " {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__decision_function_shape': 'ovo', 'clf__gamma': 1e-07, 'clf__kernel': 'linear', 'vect__min_df': 0.001, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for svm\n",
    "from sklearn.svm import SVC\n",
    "pipe_svm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf',   SVC()),\n",
    "])\n",
    "\n",
    "parameters_svm = {\n",
    "    'vect__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'vect__ngram_range': [(1, 2)],  # unigrams or bigrams\n",
    "    \"clf__C\": [0.1,1,10],\n",
    "    \"clf__kernel\":['linear'],\n",
    "    \"clf__class_weight\" : ['balanced'],\n",
    "    \"clf__decision_function_shape\":['ovo'],\n",
    "    \"clf__gamma\":[1e-07,1e-06,1e-05]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=parameters_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_svm.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.646\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 1000, 'clf__min_samples_split': 20, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for random forest take 2\n",
    "\n",
    "pipe_rf2 = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "parameters_rf2 = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [1.0],\n",
    "    'tfidf__ngram_range': [(1, 2)],  #bigrams\n",
    "    \"clf__criterion\": [\"gini\"],\n",
    "    \"clf__max_depth\":[500,1000],\n",
    "    \"clf__min_samples_split\" : [20,30,40]\n",
    "}\n",
    "\n",
    "gs_rf2 = GridSearchCV(estimator=pipe_rf2,\n",
    "            param_grid=parameters_rf2,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_rf2.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_rf2.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.530\n",
      "\n",
      "Best params:\n",
      " {'clf__metric': 'minkowski', 'clf__n_neighbors': 15, 'svd__n_components': 75, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for knn\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "    ('clf',   KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "parameters_knn = {\n",
    "    'tfidf__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1,1),(1, 2)],  #  bigrams\n",
    "    \"svd__n_components\": [50,75,100],\n",
    "    \"clf__n_neighbors\": [5,10,15],\n",
    "    \"clf__metric\": ['minkowski']\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(estimator=pipe_knn,\n",
    "            param_grid=parameters_knn,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_knn.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.703\n",
      "\n",
      "Best params:\n",
      " {'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'vect__min_df': 0.001, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for SGD\n",
    "\n",
    "pipe_sgd = Pipeline([\n",
    "    ('vect',CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf',   SGDClassifier()),\n",
    "])\n",
    "\n",
    "parameters_sgd = {\n",
    "    'vect__min_df': [0.001],\n",
    "#     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'vect__ngram_range': [(1,1),(1, 2)],  #  bigrams\n",
    "#     \"clf__n_neighbors\": [5,10,15],\n",
    "#     \"clf__metric\": ['minkowski']\n",
    "    \"clf__penalty\": ['l2','l1','elasticnet'],\n",
    "    \"clf__loss\":['hinge','log','perceptron'],\n",
    "    \"clf__alpha\":[1e-3,1e-2,1e-1]\n",
    "}\n",
    "\n",
    "gs_sgd = GridSearchCV(estimator=pipe_sgd,\n",
    "            param_grid=parameters_sgd,\n",
    "            scoring='accuracy',\n",
    "            cv=KFold(5,shuffle=True,random_state=42), \n",
    "            return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Fit using grid search\n",
    "best_model = gs_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs_sgd.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_sgd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for xgboost\n",
    "\n",
    "# pipe_xgb = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(min_df=0.001)),\n",
    "#     ('svd',   TruncatedSVD(algorithm='randomized')),\n",
    "#     ('clf',   XGBClassifier(objective='multi:softmax', num_class=20)),\n",
    "# ])\n",
    "\n",
    "# parameters_xgb = {\n",
    "# #     'tfidf__min_df': [0.001],\n",
    "# #     'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "#     'tfidf__ngram_range': [(1,2),(1, 2)],  #  bigrams\n",
    "#     \"svd__n_components\": [500],\n",
    "#     \"clf__n_estimators\": [500],\n",
    "#     \"clf__learning_rate\":[0.01,0.1,1],\n",
    "#     \"clf__min_samples_split\" : [50,100]\n",
    "# }\n",
    "\n",
    "# gs_xgb = GridSearchCV(estimator=pipe_xgb,\n",
    "#             param_grid=parameters_xgb,\n",
    "#             scoring='accuracy',\n",
    "#             cv=KFold(5,shuffle=True,random_state=42), \n",
    "#             return_train_score = True, verbose=1,n_jobs=-1)\n",
    "\n",
    "# # Fit using grid search\n",
    "# best_model = gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "# # Best accuracy\n",
    "# print('Best accuracy: %.3f' % gs_xgb.best_score_)\n",
    "\n",
    "# # Best params\n",
    "# print('\\nBest params:\\n', gs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
